\relax 
\providecommand\zref@newlabel[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Logistic Regression}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Bayesâ€™ Rule}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Maximum Likelihood Estimation}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}L2 Regularization}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Digit Classification}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}k-Nearest Neighbours}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces correct rate for different values of k on validation set (blue line) and k*-2, k*, k*+2 on test set (green line)}}{3}}
\newlabel{fig1}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Logistic regression}{3}}
\pgfsyspdfmark {pgfid1}{5317059}{8457947}
\pgfsyspdfmark {pgfid2}{5207809}{46725703}
\@writefile{toc}{\contentsline {paragraph}{Learning rate}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Cross-entropy of different learning rate on training set and validation set.}}{4}}
\newlabel{fig2}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Fraction of correct predictions for different learning rate on training set and validation set.}}{5}}
\newlabel{fig3}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cross-entropy of different learning rate on small training set and validation set.}}{5}}
\newlabel{fig4}{{4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Fraction of correct predictions for different learning rate on small training set and validation set.}}{6}}
\newlabel{fig5}{{5}{6}}
\@writefile{toc}{\contentsline {paragraph}{Weights initialization}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Cross-entropy of different initial weights on training set and validation set.}}{6}}
\newlabel{fig6}{{6}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Fraction of correct predictions different initial weights on training set and validation set.}}{7}}
\newlabel{fig7}{{7}{7}}
\@writefile{toc}{\contentsline {paragraph}{Times of iteration}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Cross-entropy and fraction of correct predictions of different iteration times on training set and validation set.}}{7}}
\newlabel{fig8}{{8}{7}}
\pgfsyspdfmark {pgfid3}{5317059}{39386342}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Cross-entropy change when training with minist\_train.}}{8}}
\newlabel{fig9}{{9}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Cross-entropy change when training with minist\_train\_small.}}{8}}
\newlabel{fig10}{{10}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Penalized logistic regression}{8}}
\pgfsyspdfmark {pgfid4}{5317059}{37314895}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Cross-entropy (left) and fraction of correct predictions (right) when increase $\lambda $.}}{9}}
\newlabel{fig11}{{11}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Cross-entropy (left) and fraction of correct predictions (right) when increase $\lambda $ on smaller training set.}}{9}}
\newlabel{fig12}{{12}{9}}
\pgfsyspdfmark {pgfid5}{5317059}{36240614}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Average cross-entropy (left) and classification error (right) when training on the bigger training set.}}{10}}
\newlabel{fig13}{{13}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Average cross-entropy (left) and classification error (right) when training on the smaller training set.}}{10}}
\newlabel{fig14}{{14}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Naive Bayes}{11}}
\pgfsyspdfmark {pgfid6}{5317059}{44418524}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Visualization of the mean vectors $\mu _c$.}}{11}}
\newlabel{fig15}{{15}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Visualization of the variance vectors $\sigma _c^2$.}}{11}}
\newlabel{fig16}{{16}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Compare k-NN, Logistic Regression, and Naive Bayes}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Stochastic Subgradient Methods}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Averaging and Step-size Strategies}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Performance of objective function with SGD.}}{12}}
\newlabel{fig17}{{17}{12}}
\pgfsyspdfmark {pgfid7}{5317059}{8730169}
\@writefile{toc}{\contentsline {paragraph}{1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Performance of objective function with averaging.}}{13}}
\newlabel{fig18}{{18}{13}}
\pgfsyspdfmark {pgfid8}{5317059}{11988574}
\@writefile{toc}{\contentsline {paragraph}{2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Performance of objective function with "second-half" averaging.}}{14}}
\newlabel{fig19}{{19}{14}}
\pgfsyspdfmark {pgfid9}{5317059}{23018202}
\@writefile{toc}{\contentsline {paragraph}{3}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Performance of objective function with $\lambda $ magnified to 1000 times.}}{15}}
\newlabel{fig20}{{20}{15}}
\pgfsyspdfmark {pgfid10}{5317059}{31155801}
